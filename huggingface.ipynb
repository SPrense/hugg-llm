{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "675aea14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T04:52:53.464142Z",
     "start_time": "2024-03-11T04:52:53.456903Z"
    }
   },
   "source": [
    "# LLM-Bert\n",
    "    - BertModel and tokenizer\n",
    "    - Bert 是一个encoder-only的pretrained模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "787bb951",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T08:04:24.384584Z",
     "start_time": "2024-04-08T08:04:24.380785Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b3a6ad2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T15:34:51.980292Z",
     "start_time": "2024-04-07T15:34:51.977818Z"
    }
   },
   "outputs": [],
   "source": [
    "import tqdm as notebook_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14347ecb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T15:53:17.497297Z",
     "start_time": "2024-04-07T15:53:17.094686Z"
    }
   },
   "outputs": [],
   "source": [
    "check_point = '/Users/hanlinwang/Downloads/bert-base-chinese/' \n",
    "tokenizer = BertTokenizer.from_pretrained(check_point)\n",
    "model = BertModel.from_pretrained(check_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f33ed87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T04:53:49.453765Z",
     "start_time": "2024-03-11T04:53:49.451013Z"
    }
   },
   "source": [
    "## Bert模型的参数\n",
    "    - 三种embeddding层构成，包括了word_embedding(词嵌入)\\token_type_embedding(多句情况下的分句标志)\\position_embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04edef3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T15:53:19.679723Z",
     "start_time": "2024-04-07T15:53:19.666845Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df774fce",
   "metadata": {},
   "source": [
    "## bert-base-uncased结构、参数设置\n",
    "- BertModel(\n",
    "  - (embeddings): BertEmbeddings(\n",
    "    - (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
    "    - (position_embeddings): Embedding(512, 768)\n",
    "    - (token_type_embeddings): Embedding(2, 768)\n",
    "    - (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "    - (dropout): Dropout(p=0.1, inplace=False)\n",
    "  - )\n",
    "  - (encoder): BertEncoder(\n",
    "    - (layer): ModuleList(\n",
    "      - (0-11): 12 x BertLayer(\n",
    "        - (attention): BertAttention(\n",
    "          - (self): BertSelfAttention(\n",
    "            - (query): Linear(in_features=768, out_features=768, bias=True)\n",
    "            - (key): Linear(in_features=768, out_features=768, bias=True)\n",
    "            - (value): Linear(in_features=768, out_features=768, bias=True)\n",
    "            - (dropout): Dropout(p=0.1, inplace=False)\n",
    "          - )\n",
    "          - (output): BertSelfOutput(\n",
    "            - (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "            - (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "            - (dropout): Dropout(p=0.1, inplace=False)\n",
    "          - )\n",
    "        - )\n",
    "        - (intermediate): BertIntermediate(\n",
    "          - (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
    "          - (intermediate_act_fn): GELUActivation()\n",
    "        - )\n",
    "        - (output): BertOutput(\n",
    "          - (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
    "          - (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "          - (dropout): Dropout(p=0.1, inplace=False)\n",
    "        - )\n",
    "      - )\n",
    "    - )\n",
    "  - )\n",
    "  - (pooler): BertPooler(\n",
    "    - (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "    - (activation): Tanh()\n",
    "  - )\n",
    "- )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2f8c11",
   "metadata": {},
   "source": [
    "## 样例测试\n",
    "    - 经过tokenizer之后的变量的类型以及它的属性\n",
    "    - 属性有：\n",
    "        - input_ids: list 字编码\n",
    "        - attention_mask: list 掩码\n",
    "        - token_type_ids: list 分词编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cad85ed1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T14:41:49.475825Z",
     "start_time": "2024-03-23T14:41:49.473760Z"
    }
   },
   "outputs": [],
   "source": [
    "text = 'what is the fox,that is fork.'\n",
    "encoder_input = tokenizer(text, return_tensors='pt') # 这里要注意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6910f8a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T14:47:29.410520Z",
     "start_time": "2024-03-23T14:47:29.365181Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2054, 2003, 1996, 4419, 1010, 2008, 2003, 9292, 1012,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c236fe08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T14:41:50.963692Z",
     "start_time": "2024-03-23T14:41:50.868898Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder_outputs = model(**encoder_input,output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "07f19e44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T14:41:51.927367Z",
     "start_time": "2024-03-23T14:41:51.921792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768]) torch.Size([1, 11, 768])\n"
     ]
    }
   ],
   "source": [
    "print(encoder_outputs.pooler_output.size(),encoder_outputs.last_hidden_state.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f466abf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T05:03:35.364633Z",
     "start_time": "2024-03-11T05:03:35.357131Z"
    }
   },
   "source": [
    "### token embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a6543be9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T05:19:58.638664Z",
     "start_time": "2024-03-11T05:19:58.632451Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 2054, 2003, 1996, 4419,  102]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = encoder_input['input_ids']\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "afda09ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T05:20:02.994254Z",
     "start_time": "2024-03-11T05:20:02.987269Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0136, -0.0265, -0.0235,  ...,  0.0087,  0.0071,  0.0151],\n",
       "         [ 0.0387,  0.0035, -0.0619,  ...,  0.0192, -0.0217, -0.0888],\n",
       "         [-0.0360, -0.0246, -0.0257,  ...,  0.0034, -0.0018,  0.0269],\n",
       "         [-0.0446,  0.0061, -0.0022,  ..., -0.0363, -0.0004, -0.0306],\n",
       "         [-0.0700, -0.0145, -0.0065,  ..., -0.0648, -0.0418, -0.0185],\n",
       "         [-0.0145, -0.0100,  0.0060,  ..., -0.0250,  0.0046, -0.0015]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embed = model.embeddings.word_embeddings(input_ids)\n",
    "token_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3846eaf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T05:20:04.483664Z",
     "start_time": "2024-03-11T05:20:04.478853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 768])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92ce6c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T05:09:39.969608Z",
     "start_time": "2024-03-11T05:09:39.967299Z"
    }
   },
   "source": [
    "### segment embedding \\ token_type_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e184f99f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T05:20:24.411472Z",
     "start_time": "2024-03-11T05:20:24.406539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_type_embed = encoded_input['token_type_ids']\n",
    "token_type_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "79baabc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T05:20:32.107911Z",
     "start_time": "2024-03-11T05:20:32.101502Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0004,  0.0110,  0.0037,  ..., -0.0066, -0.0034, -0.0086],\n",
       "         [ 0.0004,  0.0110,  0.0037,  ..., -0.0066, -0.0034, -0.0086],\n",
       "         [ 0.0004,  0.0110,  0.0037,  ..., -0.0066, -0.0034, -0.0086],\n",
       "         ...,\n",
       "         [ 0.0004,  0.0110,  0.0037,  ..., -0.0066, -0.0034, -0.0086],\n",
       "         [ 0.0004,  0.0110,  0.0037,  ..., -0.0066, -0.0034, -0.0086],\n",
       "         [ 0.0004,  0.0110,  0.0037,  ..., -0.0066, -0.0034, -0.0086]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_embed = model.embeddings.token_type_embeddings(token_type_embed)\n",
    "segment_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9114844c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T05:20:33.120519Z",
     "start_time": "2024-03-11T05:20:33.112943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 768])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_embed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4966833",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T05:13:14.425050Z",
     "start_time": "2024-03-11T05:13:14.422495Z"
    }
   },
   "source": [
    "### position embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b2a7c75d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T05:20:43.800426Z",
     "start_time": "2024-03-11T05:20:43.794900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_ids = torch.arange(input_ids.shape[1])\n",
    "pos_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8f7d215f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T05:20:44.733684Z",
     "start_time": "2024-03-11T05:20:44.726482Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7505e-02, -2.5631e-02, -3.6642e-02,  ...,  3.3437e-05,\n",
       "          6.8312e-04,  1.5441e-02],\n",
       "        [ 7.7580e-03,  2.2613e-03, -1.9444e-02,  ...,  2.8910e-02,\n",
       "          2.9753e-02, -5.3247e-03],\n",
       "        [-1.1287e-02, -1.9644e-03, -1.1573e-02,  ...,  1.4908e-02,\n",
       "          1.8741e-02, -7.3140e-03],\n",
       "        [-4.1949e-03, -1.1852e-02, -2.1180e-02,  ...,  2.2455e-02,\n",
       "          5.2826e-03, -1.9723e-03],\n",
       "        [-5.6087e-03, -1.0445e-02, -7.2288e-03,  ...,  2.0837e-02,\n",
       "          3.5402e-03,  4.7708e-03],\n",
       "        [-3.0871e-03, -1.8956e-02, -1.8930e-02,  ...,  7.4045e-03,\n",
       "          2.0183e-02,  3.4077e-03]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_embed = model.embeddings.position_embeddings(pos_ids)\n",
    "pos_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a0744759",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T05:20:47.028724Z",
     "start_time": "2024-03-11T05:20:47.024507Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 768])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_embed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699310ae",
   "metadata": {},
   "source": [
    "### input embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c492ff6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T05:22:34.587347Z",
     "start_time": "2024-03-11T05:22:34.505027Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (6) must match the size of tensor b (8) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m input_embed \u001b[38;5;241m=\u001b[39m \u001b[43mtoken_embed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msegment_embed\u001b[49m \u001b[38;5;241m+\u001b[39m pos_embed\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (6) must match the size of tensor b (8) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "input_embed = token_embed + segment_embed + pos_embed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a548b4c5",
   "metadata": {},
   "source": [
    "# textclassfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b7813293",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T08:05:18.814522Z",
     "start_time": "2024-04-08T08:05:17.661833Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data=pd.read_csv('/Users/hanlinwang/Documents/GitHub/hugg-llm/data/cnews/cnews_train.txt',sep='\\t',names=['label','content'])\n",
    "# test_data=pd.read_csv('cnews/cnews.test.txt',sep='\\t',names=['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dacae111",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T08:22:19.679155Z",
     "start_time": "2024-04-08T08:22:19.453889Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data['len'] = [len(train_data.loc[i,'content']) for i in range(len(train_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0956b10e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T08:31:06.417147Z",
     "start_time": "2024-04-08T08:31:06.354068Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31252"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data['len']>512]['len'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e637490b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T08:24:08.884255Z",
     "start_time": "2024-04-08T08:24:08.871849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "len\n",
       "93      71\n",
       "78      68\n",
       "77      68\n",
       "106     61\n",
       "74      60\n",
       "        ..\n",
       "4385     1\n",
       "4885     1\n",
       "3736     1\n",
       "5587     1\n",
       "3212     1\n",
       "Name: count, Length: 4025, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['len'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4fee4185",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T02:33:21.283706Z",
     "start_time": "2024-04-08T02:33:21.259962Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "class MLMDataLoader:\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset,\n",
    "        batch_size=16,\n",
    "        max_length=512,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        device=None,\n",
    "        tokenizer_name='bert-base-chinese'\n",
    "    ):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.max_length = max_length\n",
    "        self.shuffle = shuffle\n",
    "        self.drop_last = drop_last\n",
    "\n",
    "        if device is None:\n",
    "            self.device = torch.device(\n",
    "                'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            )\n",
    "        else:\n",
    "            self.device = device\n",
    "\n",
    "        self.loader = DataLoader(\n",
    "            dataset=self.dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            collate_fn=self.collate_fn,\n",
    "            shuffle=self.shuffle,\n",
    "            drop_last=self.drop_last\n",
    "        )\n",
    "\n",
    "    def collate_fn(self, data):\n",
    "        sents = [i[0] for i in data]\n",
    "        labels = [i[1] for i in data]\n",
    "\n",
    "        data = self.tokenizer.batch_encode_plus(\n",
    "            batch_text_or_text_pairs=sents,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt',\n",
    "            return_length=True\n",
    "        )\n",
    "        input_ids = data['input_ids'].to(self.device)\n",
    "        attention_mask = data['attention_mask'].to(self.device)\n",
    "        token_type_ids = data['token_type_ids'].to(self.device)\n",
    "        labels = torch.LongTensor(labels).to(self.device)\n",
    "\n",
    "        return input_ids, attention_mask, token_type_ids, labels\n",
    "\n",
    "    def __iter__(self):\n",
    "        for data in self.loader:\n",
    "            yield data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "45e4fe15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T02:18:57.265346Z",
     "start_time": "2024-04-08T02:18:57.256645Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch  \n",
    "from torch.utils.data import Dataset, DataLoader  \n",
    "  \n",
    "class NewsDataset(Dataset):  \n",
    "    def __init__(\n",
    "        self, \n",
    "        categories, \n",
    "        contents, \n",
    "        tokenizer,\n",
    "        check_point_name,\n",
    "    ):  \n",
    "        self.tokenizer = tokenizer.pretrained_from(check_point_name) \n",
    "        self.categories = categories\n",
    "        self.contents = contents   \n",
    "  \n",
    "    def __len__(self):  \n",
    "        return len(self.categories)  \n",
    "  \n",
    "    def __getitem__(self, idx):  \n",
    "        category = self.categories[idx]  \n",
    "        content = self.contents[idx]  \n",
    "  \n",
    "        encoding = tokenizer(self.contents, return_tensors='pt') \n",
    "        input_ids = torch.tensor(encoding['input_ids'].flatten())  \n",
    "        attention_mask = encoding['attention_mask'].flatten()  \n",
    "        category = torch.tensor(category, dtype=torch.long)  \n",
    "  \n",
    "        return input_ids,  attention_mask, category  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5501011d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T16:09:04.459000Z",
     "start_time": "2024-04-07T16:09:04.443959Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class Bertmulticls(nn.Module):\n",
    "    def __init__(self, BertModel, check_point_name, hidden_size1, hidden_size2,dropout_rate):\n",
    "        super(Bertmulticls, self).__init__()  \n",
    "        self.bert = BertModel\n",
    "        self.linear1 = nn.Linear(768,hidden_size1)\n",
    "        self.linear2 = nn.Linear(hidden_size1,hidden_size2)\n",
    "        self.linear3 = nn.Linear(hidden_size2,1)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self,input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)  \n",
    "        sequence_output = outputs.last_hidden_state  \n",
    "        cls_output = sequence_output[:, 0, :]\n",
    "        x = encoder_outputs.pooler_output\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3829af10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T02:17:51.562444Z",
     "start_time": "2024-04-08T02:17:51.553499Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_iter, epoches):\n",
    "    model.train()\n",
    "    for epoch in range(epoches):\n",
    "        epoch_loss = 0.0\n",
    "        for input_ids, attention_mask,label in train_iter:\n",
    "            optimizer.zero_grad()\n",
    "            cls = model(input_ids = input_ids,attention_mask = attention_mask)\n",
    "            loss = criterion(cls,label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        average_loss = epoch_loss / len(train_iter)\n",
    "        print(f\"Epoch {epoch+1}/{epoches},Loss:{average_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "384588d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T16:03:06.535506Z",
     "start_time": "2024-04-07T16:03:06.529503Z"
    }
   },
   "outputs": [],
   "source": [
    "check_point_name = '/Users/hanlinwang/Downloads/bert-base-chinese/' \n",
    "categories = train_data['label']\n",
    "contents = train_data['content']\n",
    "batch_size = 16\n",
    "hidden_size1 = 256\n",
    "hidden_size2 = 64\n",
    "dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "241fdefb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T16:28:50.981735Z",
     "start_time": "2024-04-07T16:28:50.431595Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn  \n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import AdamW\n",
    "tokenizer = BertTokenizer.from_pretrained(check_point_name)\n",
    "BertModel = BertModel.from_pretrained(check_point_name,num_labels = 10)\n",
    "dataset_train = NewsDataset(categories, contents, tokenizer)  \n",
    "train_iter = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)  \n",
    "model = Bertmulticls(BertModel=BertModel,\n",
    "    check_point_name = check_point_name, \n",
    "    hidden_size1 = hidden_size1, \n",
    "    hidden_size2 = hidden_size2,\n",
    "    dropout_rate = dropout_rate\n",
    ")\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f3cc7c54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T02:19:00.136384Z",
     "start_time": "2024-04-08T02:19:00.052054Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBertModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[57], line 5\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, train_iter, epoches)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epoches):\n\u001b[1;32m      4\u001b[0m     epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m input_ids, attention_mask,label \u001b[38;5;129;01min\u001b[39;00m train_iter:\n\u001b[1;32m      6\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m model(input_ids \u001b[38;5;241m=\u001b[39m input_ids,attention_mask \u001b[38;5;241m=\u001b[39m attention_mask)\n",
      "File \u001b[0;32m~/Documents/anaconda/anaconda3/envs/LLM/lib/python3.8/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Documents/anaconda/anaconda3/envs/LLM/lib/python3.8/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Documents/anaconda/anaconda3/envs/LLM/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Documents/anaconda/anaconda3/envs/LLM/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[38], line 17\u001b[0m, in \u001b[0;36mNewsDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     14\u001b[0m category \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories[idx]  \n\u001b[1;32m     15\u001b[0m content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontents[idx]  \n\u001b[0;32m---> 17\u001b[0m encoding \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[1;32m     18\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(encoding[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mflatten())  \n\u001b[1;32m     19\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m encoding[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mflatten()  \n",
      "File \u001b[0;32m~/Documents/anaconda/anaconda3/envs/LLM/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2829\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2828\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2829\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2831\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/Documents/anaconda/anaconda3/envs/LLM/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2887\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2884\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text):\n\u001b[0;32m-> 2887\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2888\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2889\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2890\u001b[0m     )\n\u001b[1;32m   2892\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text_pair):\n\u001b[1;32m   2893\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2894\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2895\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2896\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
     ]
    }
   ],
   "source": [
    "train(BertModel, criterion, optimizer, train_iter, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8ef44b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T15:53:44.453389Z",
     "start_time": "2024-04-07T15:53:44.355654Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_category(y_train):\n",
    "    \"\"\"读取分类目录，固定\"\"\"\n",
    "    categories = ['体育', '财经', '房产', '家居', '教育', '科技', '时尚', '时政', '游戏', '娱乐']\n",
    "    categories = [x for x in categories]\n",
    "    cat_to_id = dict(zip(categories, range(len(categories))))\n",
    "    label_id = []\n",
    "    for i in range(len(y_train)):\n",
    "        label_id.append(cat_to_id[y_train[i]])\n",
    "    return label_id\n",
    "\n",
    "train_target=train_data['label']  \n",
    "train_data['label']=read_category(train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d0532c0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T07:55:30.011669Z",
     "start_time": "2024-04-08T07:55:28.255953Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/anaconda/anaconda3/envs/LLM/lib/python3.8/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Documents/anaconda/anaconda3/envs/LLM/lib/python3.8/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/anaconda/anaconda3/envs/LLM/lib/python3.8/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/Documents/anaconda/anaconda3/envs/LLM/lib/python3.8/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Documents/anaconda/anaconda3/envs/LLM/lib/python3.8/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7a9e1e8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T02:09:49.451217Z",
     "start_time": "2024-04-08T02:09:49.446387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "746"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data['content'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4514aa30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T02:11:23.836729Z",
     "start_time": "2024-04-08T02:11:23.821063Z"
    }
   },
   "outputs": [],
   "source": [
    "test = tokenizer(train_data['content'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6785e068",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T02:11:51.191175Z",
     "start_time": "2024-04-08T02:11:51.185455Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "739"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test.input_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
